{"cells":[{"cell_type":"code","source":["# Before we begin, confirm all files are loaded\ndisplay(dbutils.fs.ls(\"dbfs:/FileStore/tables/\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"78f9aa64-a707-4df5-a57d-b7fdc683a774"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["# Mod 04 - Complex Data Types (Array, Map, Struct)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"41ec7600-d7b4-4a4e-86f0-d15fa8a80cf9"}}},{"cell_type":"markdown","source":["## Lab 01: Query an ARRAY Data type"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"964d834d-3caa-442a-addd-b66444a798da"}}},{"cell_type":"code","source":["# Lab 01a: First Load Data and create TempView\n\ndf1 = spark.read.format(\"parquet\").load(\"dbfs:/FileStore/tables/temp1.parquet/\")\ndisplay(df1)\ndf1.printSchema()\ndf1.createOrReplaceTempView(\"temp_temperature\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5ce303fb-3b7a-45f9-8bfd-9211794f6266"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Uncomment this and run if wish to run next Cell again\n# dbutils.fs.rm('/user/hive/warehouse/temperature2', True)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c6bc81d9-5c0c-484a-bf16-078b5a54d98b"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Lab 01b: Create Permanent Table from TempView\n\nspark.sql('DROP TABLE IF EXISTS temperature2')\n\nspark.sql('CREATE TABLE temperature2 AS SELECT * FROM temp_temperature')\ndisplay(spark.sql('SELECT * FROM temperature2'))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"80944652-68c0-4eb8-90ee-44d344e39892"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%sql\n-- Lab 01c: Query an ARRAY from TempView\n-- Pluck out 2 Index Number values\n\nSELECT city, mytemp[1], mytemp[2] from temp_temperature"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4a070eb2-1071-44c3-99d4-fca07b1331bd"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Lab 01d: Query ARRAY from DataFrame using 'array_contains'\n\n# First convert Hive table ot Dataframe\ndf = spark.table(\"temperature2\")\n\n# Import Library\nfrom pyspark.sql.functions import array_contains\n\n# Find row(s) where 'mytemp' Array column has value = 68\ndisplay(df.select(\"city\").where(array_contains(df.mytemp, 68.0)))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"73c19ddd-16c5-43b1-a5fc-386e5e3886ad"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Lab 02: Query an ARRAY from DataFrame using 'explode', 'explode_outer' and 'size'"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7289cd1e-490f-4e59-bfb1-8c244bf8ed07"}}},{"cell_type":"code","source":["%python\n# Lab 02a: Create DataFrame and TempView first\n\ndf1 = spark.read.format(\"parquet\").load(\"dbfs:/FileStore/tables/temp_array_null.parquet\")\n# df1 = spark.read.format(\"parquet\").load(\"dbfs:/FileStore/tables/aa_temp_array_null/\")\ndisplay(df1)\ndf1.createOrReplaceTempView(\"temp_array_null\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"62bf8214-8156-45e5-8d71-824613184731"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Uncomment this and run if wish to run next Cell again\n# dbutils.fs.rm('/user/hive/warehouse/perm_array_null2', True)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"417555d0-5543-4306-afd6-09efc682c794"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%sql\n-- Lab 02b: Create Permanent Hive table from TempView\n\nDROP TABLE IF EXISTS perm_array_null2;\n\nCREATE TABLE perm_array_null2 as SELECT * FROM temp_array_null;\n\nSELECT * FROM perm_array_null2;"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b41f374b-ed46-4b72-a278-f87428aa088e"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%py\n# Lab 02c: Query ARRAY data type using 'explode', 'explode_outer' and 'size'\n\n\nfrom pyspark.sql.functions import explode, explode_outer, size\n\ndf = spark.table(\"perm_array_null2\")\ndisplay(df)\n\n# 'explode' will not display the NULL Array rows\ndisplay(df.select(\"city\", explode(\"mytemp\")))\n\n# 'explode_outer' will display the NULL Array rows\ndisplay(df.select(\"city\", explode_outer(\"mytemp\")))\n\n# 'size' will count values in Array (-1 = Null Array)\ndisplay(df.select(\"city\", size(\"mytemp\")))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e092b880-a765-46eb-81cc-8ced56ce4a26"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Lab 03: Reverse on an ARRAY"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2bb1c855-ee39-47df-bf8a-4e44c73effe8"}}},{"cell_type":"code","source":["%py\n# Lab 03a: Create TempView from DataFrame\n \ndf1 = spark.read.format(\"json\").load(\"dbfs:/FileStore/tables/state_city.json/\")\ndisplay(df1)\ndf1.printSchema()\ndf1.createOrReplaceTempView(\"temp_state_city\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a21873e4-d2e6-4908-85cc-d92f29584640"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%python\n# Lab 03b: Reverse 'city' Array data type\nfrom pyspark.sql.functions import reverse\n\ndisplay(df1.select(reverse(\"city\")))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a93d3b60-6e8e-4f54-93f7-48feb7343b7a"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Lab 04: Create ARRAY on-the-fly (Both Scala and Python)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"454eebe3-55a3-4819-a89f-b7c06926afe0"}}},{"cell_type":"code","source":["%scala\n// Lab 04a: Using Scala, create ARRAY data type\n\nimport org.apache.spark.sql.functions._\n\nval df = Seq(\n  (\"beatles\", \"help|penny lane\"),\n  (\"supertramp\", \"breakfast in america\")\n).toDF(\"name\", \"songs\")\n\nval bandDF = df.withColumn(\n        \"songs\",\n        split(col(\"songs\"), \"\\\\|\"))\n\n\nbandDF.show(2, false)\n\nbandDF.printSchema()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"27f6bdbb-d946-4436-bc0f-f3b0d003388e"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Lab 04b: Using Python, create ARRAY data type\n\ndf = spark.createDataFrame([ ([1,2,2,3],), ([4,4,5,5],)], ['data'])\ndf.printSchema()\n\ndf.show(10, False)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9a881bf4-8eea-48c6-988a-11240bdbdadc"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Lab 05: MAP Data types"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"46e8926e-2572-4425-9eb9-90a5fb0272d9"}}},{"cell_type":"code","source":["# Lab 05a: Load Data and create TempView\n\ndf1 = spark.read.format(\"parquet\").load(\"dbfs:/FileStore/tables/school1.parquet/\")\ndisplay(df1)          \ndf1.printSchema()\ndf1.createOrReplaceTempView(\"temp_school\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"71488a1a-62d3-4db6-88a6-7f77945e1e78"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%sql\n-- Lab 05b: Pluck out Values for 'Math' Key\n\nSELECT name, grades['Math'] FROM temp_school;"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bc1960d6-12f0-473d-ba9b-e5a9a6668ba3"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%sql\n-- Lab 05c: 'explode' out all Values from all Keys in 'grade' MAP column\n\nSELECT name, explode(grades) FROM temp_school;"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bf112bf7-a0df-42fd-9c53-359a1d841ccc"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Lab 05d: map_keys\n\nfrom pyspark.sql.functions import map_keys\n\ndisplay(df1.select(map_keys(\"grades\")))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0cd88053-47c0-4a2f-a821-9405ed16f4a5"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Lab 05e: map_values\n\nfrom pyspark.sql.functions import map_values\n\ndisplay(df1.select(map_values(\"grades\")))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"51417dad-ba89-4e24-a5a9-bac5a7233559"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Lab 06: Create Map DataFrame using 'create_map'"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0e852316-e081-476a-b2f1-98cf5fada6e0"}}},{"cell_type":"code","source":["# Lab 06a: Create MAP data type from File\nfrom pyspark.sql.functions import create_map\n\ndf1 = spark.read.csv(\"dbfs:/FileStore/tables/names1.csv\", inferSchema=True, header=True)\n\ndf1.printSchema()\n\ndf1.show(5, False)\n\ndf2 = df1.select(create_map(\"k1\", \"v1\", \"k2\", \"v2\").alias(\"kv\"))\ndf2.printSchema()\n\ndf2.show(5, False)\n\ndf2.select (\"kv.name\").show(5, False)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"eb777a92-38ef-4aeb-b484-b581e64d3e4b"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%sql\n-- Lab 06b: First CREATE TABLE of all your KV pairs\n-- Must use STRING data type since can have variable KV pairs \n\nDROP TABLE IF EXISTS demo1;\n\nCREATE TABLE demo1 (k1 string, v1 string, k2 string, v2 string) \nUSING CSV \nOPTIONS (path \"dbfs:/FileStore/tables/names.txt\", header = False);\n\nSELECT * FROM demo1;"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"48153c00-3a7e-4512-8817-831c72befdee"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Lab 06c: (Con't) Convert Table to DataFrame, then convert KV pair to MAP data type\ndemoDF = spark.sql(\"SELECT * FROM demo1\")\n\ndemoDF = demoDF.select(create_map(\"k1\", \"v1\", \"k2\", \"v2\").alias(\"kv\"))\ndemoDF.printSchema()\n\ndisplay(demoDF)\ndisplay(demoDF.select(\"kv.name\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5fe74c00-677e-4fe9-9a0d-281899dd58e9"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Lab 07: \"STRUCTS\" Data type"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9e95caf4-71ed-48ac-9fb6-b43ceb9e9b3c"}}},{"cell_type":"code","source":["# Lab 07a: Query STRUCT on a DataFrame\n\ndf1 = spark.read.parquet(\"dbfs:/FileStore/tables/auto1.parquet/\")\ndf1.createOrReplaceTempView(\"temp_auto\")\n\ndisplay(df1)\ndisplay(df1.select(\"name\", \"attrib.mpg\", \"attrib.trans\"))\ndf1.printSchema()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9ce4b00d-24a1-4e36-9bf5-1c0f002ce8e6"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%sql\n-- Lab 07b: Query 'STRUCT' on TempView\nSELECT name, attrib.wt, attrib.trans FROM temp_auto;"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5b7a432c-9755-4a36-922c-2faefc5e5193"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Lab 08: Putting it All Together"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b76b9810-b044-4bb8-8d67-96f0d6fddf34"}}},{"cell_type":"code","source":["%py\n# Lab 08a:\n# Fix:  Ensure students have Line 5 correctly codes\n\ncomplex_df = spark.read.parquet(\"/FileStore/tables/emp1.parquet/\")\n\ncomplex_df.printSchema()\ndisplay(complex_df)\ncomplex_df.createOrReplaceTempView(\"temp_complex\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bb63dee0-1e22-480f-a809-34b4452c694f"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%py\n# Lab 08b\n\ndisplay(spark.sql(\"SELECT * FROM temp_complex\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b97f88d9-8f33-479e-b081-58d308ecb199"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%py\n# Lab 08c: From ARRAY, Pluck out Index 1 from the ARRAY 'subordinates' column\n\ndisplay(spark.sql(\"SELECT name, subordinates[1] FROM temp_complex\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"55ff32b1-d33f-4b7c-a7ce-af58b1d2d3ae"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%sql\n\n-- Lab 08d: From MAP, Pluck out 'Value' for a 'Key' from the MAP 'deductions' column\nSELECT name, deductions.Insurance FROM temp_complex;"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"86baa891-93cb-48cd-b633-1e210e3173d0"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%sql\n\n-- Lab 08e:From STRUCT, Pluck out 'city' and 'state from the STRUCT 'address' column\nSELECT name, address.city, address.state FROM temp_complex;"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7bb8d4b3-6d89-46fd-a792-26ae309de48d"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%sql\n-- Lab 08f: 'explode' on an ARRAY \n\nSELECT explode(subordinates) FROM temp_complex;"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7c3ff37c-b61f-45a8-be22-9e53331a125a"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%sql\n-- Lab 08g: 'explode' on a MAP\n\nSELECT explode(deductions) FROM temp_complex;"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7c83067b-c0e5-4703-a342-f9d72d1e4a5f"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["# End of Module 04: Complex Data Types\n### Ignore past here"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"004bcd7b-6d61-4340-bb98-b3fa7cb602a7"}}},{"cell_type":"code","source":["%sql\n\n--DROP TABLE IF EXISTS employees2;\n\n-- Optional way of doing it, but no need for Schema to be defined since Parquet carries Schema automatically\n--CREATE TABLE employees2 (\n--      name         STRING, salary  FLOAT,\n--      subordinates ARRAY<STRING>,\n--      deductions   MAP<STRING, FLOAT>,\n--      address      STRUCT<street:STRING,city:STRING,state:STRING, zip:INT>)\n--USING PARQUET\n--OPTIONS (path \"/FileStore/tables/aa_emp_parquet2/\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"35cb5339-7c43-4ced-aded-d1bdb9cde525"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%sql\n--DESCRIBE employees2;"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"dd7d73a3-eaac-4417-9d75-3e156dca5b92"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%sql\n--SELECT * from employees2"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"93e5a9e6-7af6-4474-a104-923b4529433c"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%py \n\n# How to query in SQL from Python via 'spark.sql'\n\n#fly1_df = spark.sql(\"SELECT * FROM flights_abbr\")\n#display(fly1_df)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cdfa327f-bc02-4a89-aa13-28fbb1ad3103"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%py\n\n# 'fly2' folder created automatically\n#fly1_df.write.parquet(\"/FileStore/tables/fly2/\", mode = \"overwrite\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f934694f-2cc6-4de6-946c-4d369e449912"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%python\n#fly2_df = spark.read.parquet(\"/FileStore/tables/fly2/\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ac800efa-6595-4002-9c95-8319218869b1"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%scala\n// Note must have TSV file loaded first\n//val rdd7 = sc.textFile(\"dbfs:/FileStore/tables/site02_201410.tsv\")\t\t\n\n//Split by tab-delimited, then replace TSV with CSV, then Save to Directory\n//val rdd8 = rdd7.map(x => x.split(\"\\t\"))\n//val rdd9 = rdd8.map(x=>x.mkString(\",\"))\t\t\n// rdd9.saveAsTextFile(\"dbfs:/FileStore/tables/fly3\")\n// Create DataFrame via Schema, then remove all NULLs\n\n//import org.apache.spark.sql.DataFrame\n//import org.apache.spark.sql.functions._\n//import org.apache.spark.sql.types._\n//import org.apache.spark.sql.types.{StructType, StructField, StringType}\n//val schema1 = StructType(Array(StructField(\"k1\", StringType, true),StructField(\"v1\", StringType, true),StructField(\"k2\", StringType, true),StructField(\"v2\", //StringType, true),StructField(\"k3\", StringType, true),StructField(\"v3\", StringType, true),StructField(\"k4\", StringType, true),StructField(\"v4\", StringType, //true),StructField(\"k5\", StringType, true),StructField(\"v5\", StringType, true),StructField(\"k6\", StringType, true),StructField(\"v6\", StringType, //true),StructField(\"k7\", StringType, true),StructField(\"v7\", StringType, true),StructField(\"k8\", StringType, true),StructField(\"v8\", StringType, //true),StructField(\"k9\", StringType, true),StructField(\"v9\", StringType, true),StructField(\"k10\", StringType, true),StructField(\"v10\",StringType, true)))\n\n//val df2 = spark.read.format(\"csv\").option(\"header\", \"false\").option(\"inferSchema\", \"false\").schema(schema1).load(\"dbfs:/FileStore/tables/site02_201410.tsv\")\n//val df3 = df2.na.fill(\"0\")\n\n// Create Map Data Type by pointing to K-V pairs via 'map' function"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"96bba819-8d7e-469e-b785-b3a0e3b49f68"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%scala\n//df3.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c1d1fa62-40e8-4ecf-a7e1-bdc0eb177b0b"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%sql\n-- CREATE TABLE employees (\n--      name         STRING, \n--      salary FLOAT,\n--      subordinates ARRAY<STRING>,\n--      deductions   MAP<STRING, STRING>,\n--      address      STRUCT<street:STRING,city:STRING,state:STRING, zip:INT>)\n--USING CSV\n--LOCATION \"dbfs:/shared_uploads/ottmk@ucmail.uc.edu/site02_201410.csv\"\n\n-- LOAD DATA local inpath '/opt/employees.txt' into table employees\n\n-- DESCRIBE employees;\n\n-- SELECT * from employees; "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7fc9d9b6-fac3-4c7a-855f-4fa648d3dbe3"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# How to write a DataFrame and/or Table to to a file\n\n#complex_df = spark.read.parquet(\"/FileStore/tables/emp_snappy.parquet\")\n\n#complex_df.printSchema()\n#complex_df.show(100, False)\n#complex_df.createOrReplaceTempView(\"temp_complex\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1377a2e4-9d56-4bd5-b549-711f7a5a63e1"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# To save a DataFrame as a file, code this:\n#complex_df = spark.read.parquet(\"/FileStore/tables/emp_snappy.parquet\")\n#complex_df.write.format(\"orc\").save(\"/FileStore/tables/complex_dir/\", mode = \"overwrite\")\n\n# To save a TempView or Hive table as a file, code this.  Files saved to : /user/warehouse/hive/<tablename>/\n#spark.sql(\"DROP TABLE IF EXISTS complex_table2\")\n#spark.sql(\"CREATE TABLE complex_table2 AS SELECT * FROM temp_complex\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6601b0a3-4b5c-4e32-a78f-a097ad2f1921"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Confirm files are written from DataFrame:\n#display(dbutils.fs.ls(\"dbfs:/FileStore/tables/complex_dir/\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6e8e7839-9fb6-4309-b1bb-5d4101c3a711"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Confirm files are written to Hive table\n#display(dbutils.fs.ls(\"dbfs:/user/hive/warehouse/complex_table2/\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"156e4764-0cf5-47f2-af37-1a60ee9cb359"}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Mod-04-Complex!","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":3262131266601176}},"nbformat":4,"nbformat_minor":0}
