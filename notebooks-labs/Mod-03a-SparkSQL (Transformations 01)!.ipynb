{"cells":[{"cell_type":"code","source":["# Lab 00: If get QUOTA EXCEEDED, run below commands to remove ALL HIVE tables\n# If need to remove files, can get rid of these\n# dbutils.fs.rm(\"dbfs:/user/hive/warehouse/\", True)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"59544efc-7605-4203-8834-f16aa126f68a"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["# Mod 03a: SparkSQL (Transformations 01)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5f380e4c-bfd4-41f4-b284-37f3aabc26aa"}}},{"cell_type":"markdown","source":["## Columns and Expressions"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"79e0105e-5619-452d-99f8-b324691ecc38"}}},{"cell_type":"code","source":["empDF = spark.read.format(\"parquet\").load(\"dbfs:/FileStore/tables/emp_snappy.parquet/\")\ndisplay(empDF)\nempDF.schema"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"da4e2bd5-5bdc-40ab-af68-2f455f7b82b6"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["deptDF = spark.read.format(\"parquet\").load(\"dbfs:/FileStore/tables/dept_snappy.parquet/\")\ndisplay(deptDF)\ndeptDF.schema"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"79168a84-9d80-4580-ab59-eaf4bc307e97"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### Using select, filter, withColumn (to add new Column) and 'col' for cast"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"816a1a43-e3ce-4b51-a13b-b6b9052dc879"}}},{"cell_type":"code","source":["from pyspark.sql.functions import *\n# Using 'col' to form Expressions (in 'cast')\n\nempDF2 = (empDF.select(\"emp\", \"mgr\", \"dept\", \"salary\")\n               .filter(\"dept > 100\")\n               .withColumn(\"NewSalary\", (col(\"salary\") * 1.10).cast(\"float\"))\n               .sort(col(\"mgr\").desc()))\n\ndisplay(empDF2)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fc2d2c49-094a-4c1e-8f13-77beb0533612"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Create DataFrame with Complex Data types so we can pluck out nested Columns\ncomplexDF = spark.read.parquet(\"/FileStore/tables/emp1.parquet/\")\n\ncomplexDF.printSchema()\ndisplay(complexDF)\ncomplexDF.createOrReplaceTempView(\"temp_complex\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"23258a99-f0b3-4eb2-a668-01bcf412ac30"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### Pluck out Nested Columns in 'address' Struct via 'col'"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e9546ff0-a1df-4a1f-8f93-74f772cae800"}}},{"cell_type":"code","source":["from pyspark.sql.functions import col\n\nlocDF = complexDF.select(\"name\",\n  col(\"address.city\").alias(\"city\"),\n  col(\"address.state\").alias(\"state\"))\n\ndisplay(locDF)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0a024fb1-2b08-45d7-a019-24f6338a09b1"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### Using 'selectExpr' to alias a Column"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0b16ed6a-ef27-45d1-a611-34ef6227ef21"}}},{"cell_type":"code","source":["# Return Boolean 'true' or 'false'\ndisplay(empDF.selectExpr(\"last_name\", \"dept\", \"dept in (401, 402) as HR_depts\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ba10e94d-4d27-4422-b86d-a251a92ca2d3"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### 'drop' removes Column from Output"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"775e35e5-1905-4da3-af58-b9639e72f7f3"}}},{"cell_type":"code","source":["display(empDF.drop(\"hire\", \"birth\", \"salary\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0fc75683-ebba-45a7-aed8-02293d56fb1b"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### 'withColumnRenamed' to change a Column (Alternative to 'alias' and 'as')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"865bb013-be76-49fe-9ae6-36079316461c"}}},{"cell_type":"code","source":["from pyspark.sql.functions import col\n\ndisplay(complexDF.select (\"name\", \"subordinates\")\n                 .withColumnRenamed(\"name\", \"FullName\")\n                 .withColumnRenamed(\"subordinates\", \"Associates\")\n       )"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c25c96dd-c5e8-4917-8cfd-a5f690426194"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### 'isNotNull' requires 'col'"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f7d47055-257a-446b-b89e-2edc18e1766e"}}},{"cell_type":"code","source":["data = [\n    (\"James\",None,\"M\"),\n    (\"Anna\",\"NY\",\"F\"),\n    (\"Julia\",None,None)\n  ]\n\ncolumns = [\"name\",\"state\",\"gender\"]\ndf = spark.createDataFrame(data,columns)\ndisplay(df)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"aa877912-fde3-46c1-b701-850f8d3e1951"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["display(df.filter(col(\"state\").isNotNull()))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0caff3d0-9597-43b3-ba15-c231b83f3415"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### Compound 'filter'"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"351411ee-88f5-486b-bbaf-47f3391eea61"}}},{"cell_type":"code","source":["display(empDF.filter((empDF.emp > 1010) & (empDF.dept == 501)))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4e40e4d6-7b03-4828-a222-efd800b34976"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### 'dropDuplicates' and 'distinct'"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3b372b6e-3a93-474f-9c1e-0125ebc9ca3f"}}},{"cell_type":"code","source":["data = [\n    (\"Mark\",\"OH\",\"M\"),\n    (\"Juli\",\"NY\",\"F\"),\n    (\"Juli\",\"NY\",\"F\")\n  ]\n\ncolumns = [\"name\",\"state\",\"gender\"]\ndf = spark.createDataFrame(data,columns)\ndisplay(df)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"090eeccd-bbdd-4356-92c9-dc6ca799db1c"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# 'distinct' drops all other columns\ndisplay(df.select(\"name\").distinct())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"17e31770-15fe-4812-b1c1-5ca329cd2165"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# 'dropDuplicates' keeps other columns\ndisplay(df.dropDuplicates([\"name\"]))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ceddb334-e342-43df-875a-ca5a7b13ce78"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["###'limit' and 'sort' and 'orderBy'"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"89248f7e-8e8f-4493-bf49-e75da363d478"}}},{"cell_type":"code","source":["# Note however that sort() method will sort the records in each partition and then return the final output \n# which means that the order of the output data is not guaranteed because the data is ordered on partition-level \n# but your DataFrame may have thousands of partitions distributed across the cluster. \n# Since the data is not collected into a single executor the sort() method is efficient \n# thus more suitable when sorting is not critical for your use-case.\n\n# Unlike sort(), the orderBy() function guarantees a total order in the output. \n# This happens because the data will be collected into a single executor in order to be sorted. \n# This means that orderBy() is more inefficient compared to sort()\n\ndisplay(empDF.sort(\"emp\").limit(10))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d6ef5a66-7fb0-4b14-89c5-2060e54a9387"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["display(empDF.orderBy(col(\"emp\").desc()))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"dbfcf244-8357-4e0c-8fc6-7c6440ebb7f1"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### Lab 01: Date and TimeStamps"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3e8514c9-c68e-4b21-9c1f-4fc6e3a114e3"}}},{"cell_type":"code","source":["eventsDF = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(\"dbfs:/FileStore/tables/webevent.csv\")\ndisplay(eventsDF)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9f86141e-d581-4a77-9fa2-7c04db1b8786"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### 'select' with Column operators\n## cast, alias, between, substring, orderBy"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1b2e213d-d90b-4c28-bfea-7b21b1bfa41e"}}},{"cell_type":"code","source":["empDF.select(empDF.salary.cast(\"string\")).limit(2).show()\n\nempDF.select(empDF.salary.alias(\"wage\")).limit(2).show()\n\nempDF.select(empDF.salary,empDF.salary.between(50000, 100000)).limit(2).show()\n\nempDF.select(empDF.salary.substr(1,4)).limit(2).show()\n\nempDF.orderBy(empDF.salary.desc()).limit(3).show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2ef8b1f5-29ef-47b9-a3c0-3a912e5da7be"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### Statistics using 'describe' and 'count'"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0707cccc-4d4b-41e0-933e-7f8ab76f565c"}}},{"cell_type":"code","source":["display(empDF.describe())\n\nempDF.count()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"513902cd-e073-42b5-852f-fcbf37ad933b"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### 'na.fill' to replace NULL values. 'drop' to remove Columns in Output"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c975460a-a445-447d-8571-145b1fafe3be"}}},{"cell_type":"code","source":["flyDF = spark.read.parquet(\"dbfs:/FileStore/tables/fly1.parquet\")\nflyDF.show()\n\nflyDF2 = flyDF.drop(\"k10\").drop(\"v10\").na.fill(\"0\")\nflyDF2.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"07c23a45-fd0a-433c-bac6-a52eab45479d"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### 'groupBy', 'count' and 'orderBy'"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c03c005f-681b-449f-a2b2-1d614efcc491"}}},{"cell_type":"code","source":["display(empDF.select(\"last_name\", \"dept\", \"salary\").filter(\"dept > 400\").groupBy(\"dept\").count().orderBy(\"dept\", ascending=False))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6f4ceca1-590c-4df9-9c5a-19243a81e0f8"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### 'groupBy' with 'aggr'"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0e6312d5-09c4-452b-96d8-3e4e6b5a5b44"}}},{"cell_type":"code","source":["display(empDF.select(\"dept\", \"salary\").groupBy(\"dept\").agg({\"*\": \"count\", \"salary\": \"max\"}))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"55924868-c13d-4563-b892-e791ff8be1c1"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### 'join'"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"57804eb1-d9e8-4604-9060-0eee76e5b167"}}},{"cell_type":"code","source":["# Lab 12a: Join column = 'dept'\ndisplay(empDF.join(deptDF, \"dept\").limit(3))\n\ndisplay(empDF.join(deptDF, \"dept\").select(\"last_name\", \"dept\", \"dept_name\").limit(4))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a9927987-cd84-4877-91bf-b6f59f54db68"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Lab 12b: Change dept 100 to 999 for next Lab (Left JOIN,)\n# Dept 999 exists in empDF2, but not deptDF now\nfrom pyspark.sql.functions import when\n\nempDF2 = empDF.withColumn(\"dept\", when(empDF[\"dept\"] == 100, 999).otherwise(empDF[\"dept\"]))\nempDF3 = empDF2.distinct().orderBy([\"dept\"], ascending=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e5f002ba-91a8-43bf-854c-bde3cd20cf33"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Lab 12c: Left-outer Join\ndisplay(empDF3.join(deptDF, \"dept\", \"left_outer\").orderBy([\"dept\"], ascending=False))\n\n# Lab 12d: Join on 2 columns:  \ndisplay(empDF3.join(deptDF, (empDF2.dept == deptDF.dept) & (empDF2.mgr == deptDF.mgr)).limit(3))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e77d987f-7e71-42ff-af97-80e4fbefd633"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### 'explain' on DataFrame"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7603df69-3997-4929-b221-97a420df5277"}}},{"cell_type":"code","source":["empDF.join(deptDF, \"dept\").select(\"last_name\", \"dept\", \"dept_name\").explain(\"formatted\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"96d7842c-585d-4e86-ab0d-29a4154229cf"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### Spark SQL Tables/Views syntax"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"dbdd3935-ebdd-44c2-8cd8-23a0c283f1c1"}}},{"cell_type":"code","source":["empDF.createOrReplaceTempView(\"emp_view\")\ndeptDF.createOrReplaceTempView(\"dept_view\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"909b1f09-85c0-4a93-818a-790a000c6874"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%sql\n\nSELECT * FROM dept_view;"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1a6e0a3e-7d37-46d7-8357-9850c37f6e48"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%sql\n-- Various functions including WHERE, BETWEEN, AS, ORDER BY\n\nSELECT emp, last_name, salary as wage \nFROM emp_view\nWHERE salary BETWEEN 50000 AND 100000\nORDER BY salary DESC;"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"34c1e8c0-ee23-46bb-914d-fc186a8c499c"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%sql\n-- Aggregations (Count and Max)\n\nSELECT dept, \n       count(*) as ct_dept, \n       max(salary) as max_sal \nFROM emp_view\nGROUP BY dept;"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"47b12468-2ecb-4304-8827-81c990a64a33"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Lab 14d: Notice all the NULL values in the Output\n\nspark.read.parquet(\"/FileStore/tables/fly1.parquet\").createOrReplaceTempView(\"fly_view\")\nspark.sql(\"SELECT * FROM fly_view\").show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e07fde24-f169-4206-848f-494a0cb17f9f"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%sql\n-- Notice NULL values in k6 Column.  Next cell will convert these NULLs to 0\n\nSELECT k1, v1, k6 FROM fly_view;"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"270a72fb-1807-45e9-b44d-59234485917d"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%sql\n-- Use 'coalesce' to convert NULL to different value\n\nSELECT k1, v1, COALESCE(k6, CAST(0 as INTEGER)) as k6 FROM fly_view;"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0fd1ddc8-27e6-460e-b2d3-a691ead24f39"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%sql\n-- JOIN\n\nSELECT * FROM emp_view as e JOIN dept_view as d\nON e.dept = d.dept;"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"06f6f9b8-48e6-415e-8a45-cd0a5f1b6c64"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%sql\n-- EXPLAIN  (Extended and Formatted)\n\nEXPLAIN FORMATTED SELECT * FROM emp_view as e LEFT OUTER JOIN dept_view as d\nON e.dept = d.dept;"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6804e112-91bc-4a07-ab82-5780f5a7fe8c"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["# End of Mod-03a-SparkSQL (Transformations 01)\n## Continue on to Notebook Mod03b-SparkSQL (Transformations 02)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"611eb5b8-4ef7-4f73-8a94-3ca256deb85c"}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Mod-03a-SparkSQL (Transformations 01)!","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":3262131266600554}},"nbformat":4,"nbformat_minor":0}
