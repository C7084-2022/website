{"cells":[{"cell_type":"code","source":["# Lab 01a: Before we begin, confirm all files are loaded\n# Should have 56 rows if you loaded everything correctly\ndisplay(dbutils.fs.ls(\"dbfs:/FileStore/tables/\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"46a51111-9459-4ba0-97f6-6fd7e6704eaf"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["# Mod 10: Performance Tuning"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"207e0806-c53f-4128-856d-5416b293e090"}}},{"cell_type":"code","source":["# Lab 00: First, disable side effects\nspark.conf.set(\"spark.databricks.io.cache.enabled\", False)\nspark.conf.set(\"spark.sql.adaptive.enabled\", False)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"99ec073d-1c5c-4262-b13a-482b086ba256"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["## Lab 01: Spark Cache"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"96cd4ebe-aa4c-4eef-b642-2367de302ab2"}}},{"cell_type":"code","source":["# Lab 01a: Viewing 'Storage' tab and 'SQL' tab after Caching\n# cache() is lazy for DataFrames, so issue count() to put DataFrame in cache()\n# On subsequent queries using this DataFrame, should\ndf1 = spark.read.format(\"delta\").load(\"/tmp/delta_colPrune/\")\ndisplay(df1)\n\n# Best to name DataFrame so Users know it's Cached\nc_DF = df1.cache()\nc_DF.count()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"903e1e10-c188-4b8f-92d8-3c86f84d74bf"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# Lab 01b:  Subsequent query faster since reading from Cache, not Files\nc_DF.count()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"116b6f98-b473-4ac9-83f0-17925577a732"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# Lab 01c: Getting Cache wrong. First, let's cache the following\ncopsCache_DF = df1.select(\"Category\", \"Description\").filter(\"IncidentNum > 150146449\").cache()\ncopsCache_DF.count()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"88a8cde7-82a5-42c7-8a9f-77f9358e0e7b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# Lab 01d: Getting Cache wrong (Cache not being used)\n# Moved 'filter' in front of the 'select'\ndisplay(copsCache_DF.filter(\"IncidentNum > 150146449\").select(\"Category\", \"Description\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f68ca1fb-c83f-4d24-a407-8559fbcd6be5"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# Lab 01e: Getting Cache wrong again (Cache not being used) \n# Filter is slightly greater than original Cache\ndisplay(copsCache_DF.select(\"Category\", \"Description\").filter(\"IncidentNum > 150146500\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"812da7d8-981f-45fc-aded-d49b7e34822a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# Lab 01f: Getting Cache wrong again (Cache not being used) \n# Only have 'Category' in 'select'\ndisplay(copsCache_DF.select(\"Category\").filter(\"IncidentNum > 150146449\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ec7a6d16-bc0e-40b0-b15d-c2e9feaca9e0"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# Lab 01g: Getting Cache right (Cache being used) \n# Using the exact Cache object I started with\ndisplay(copsCache_DF)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3a2ee844-5bb4-47b4-a5fe-f03758268951"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# Lab 01h: Perist Disk_only\n# Go to Spark UI and view DAG and 'Storage' tab\nfrom pyspark import StorageLevel\n\nspark.read.parquet(\"dbfs:/FileStore/tables/dept_snappy.parquet/\").createOrReplaceTempView(\"dept_view\")\ndeptDF = spark.table(\"dept_view\")\ncachedDeptDF = deptDF.persist(StorageLevel.DISK_ONLY)\ncachedDeptDF.count()\ndisplay(cachedDeptDF)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"dd9d79b9-eef4-44cb-b809-daea2b6ef7de"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# Lab 01i: Caching Tables\n# Go to Spark UI and view DAG and 'Storage' tab\n\nspark.sql(\"cache table dept_view\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"60123e1d-7cf0-4b74-87e0-3748e2901a0c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# Lab 01j: UnPerist a DataFrame/Table\n# Go to Spark UI and view DAG 'Storage' tab.  Object should be removed\n\nc_DF.unpersist()\ncopsCache_DF.unpersist()\nspark.sql(\"uncache table dept_view\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cd396479-edf9-4efb-9b19-f2cd193065dd"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# Lab 01k: Use catalog to remove all data from cache\nspark.catalog.clearCache()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c10f789a-6822-463b-a683-3d47a168a597"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["## Delta Cache"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e67f062f-d003-4363-8b65-490b1a11cb6a"}}},{"cell_type":"code","source":["# Lab 02a:  Go to Spark UI > Storage tab and confirm Delta Cache is empty"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3fe8b637-bc9c-4e36-a072-53dcfe780954"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# Lab 02b: Now, enable Delta Cache\nspark.conf.set(\"spark.databricks.io.cache.enabled\", True)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"68b6bdf1-474b-4310-a3f1-76929a74d409"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# Lab 02c: Read Data in to be Delta Cached\n#          Then go to Spark UI > Storage tab and confirm it has been activated\ndf1 = spark.read.format(\"delta\").load(\"/tmp/delta_colPrune/\")\ndisplay(df1)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8d6be2c9-9caa-4068-86cb-51f691c37b81"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["# 5 Most common Performance issues"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b7b4a472-e9ef-48c8-9e7b-4781f0f9d5f3"}}},{"cell_type":"markdown","source":["## Lab 01: Spill"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4e1ad9e7-c1ca-4b18-8572-fa0a90ba7984"}}},{"cell_type":"code","source":["# 01a: Here's the Data set we'll be using.  It's rather large\ndisplay(dbutils.fs.ls(\"dbfs:/databricks-datasets/asa/airlines/\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"14ec0cde-86f8-4036-9ce3-bffefc471ad6"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# 01b: Hard-code Schema\nDDL_Schema = (\"Year integer,Month integer,DayofMonth integer,DayOfWeek integer,DepTime string,CRSDepTime integer,ArrTime string,CRSArrTime integer,UniqueCarrier string,FlightNum integer,TailNum string,ActualElapsedTime string,CRSElapsedTime integer,AirTime string,ArrDelay string,DepDelay integer,Origin string,Dest string,Distance integer,TaxiIn integer,TaxiOut integer,Cancelled integer,CancellationCode string,Diverted integer,CarrierDelay string,WeatherDelay string,NASDelay string,SecurityDelay string,LateAircraftDelay string\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"aad81939-d9d5-4553-a872-467aae7c32a2"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# 01c: Force Partition size = 2GB in attempt to force Spill\nspark.conf.set(\"spark.sql.files.maxPartitionBytes\", 2005000000)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cc25c6a4-4d34-4adc-bf9f-c4b6ecdf8bc9"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# 01d: Force # of Partition = 8 via repartition() method\n# Let run for minute, then from Spark UI, go to 'Stages' tab and look for Spill\n# Then 'CANCEL' query and move on to next Cell\nflightsDF = spark.read.option(\"header\", True).schema(DDL_Schema).csv(\"dbfs:/databricks-datasets/asa/airlines/\").repartition(8)\nflightsDF.createOrReplaceTempView(\"flights_view\")\ndisplay(display(spark.sql(\"SELECT * FROM flights_view v1 UNION SELECT * FROM flights_view\")))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"12888349-a5eb-49e0-ad2f-18f645301f1a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# 01e: Configure settings back to Default and run again.  Then remove 'repartition(8)'\n#      Query now runs WITHOUT Spill\n\nspark.conf.set(\"spark.sql.files.maxPartitionBytes\", 134217728)\nflightsDF = spark.read.option(\"header\", True).schema(DDL_Schema).csv(\"dbfs:/databricks-datasets/asa/airlines/\")\nflightsDF.createOrReplaceTempView(\"flights_view\")\ndisplay(display(spark.sql(\"SELECT * FROM flights_view v1 UNION SELECT * FROM flights_view\")))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"711bd140-a653-472d-a1bf-b28494b87187"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["## Lab 02: Skew"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cd61b49c-6a16-49ba-91d0-a7c34d0973db"}}},{"cell_type":"code","source":["%scala\n// Lab 02a: Setup for Skew Partitions:  Create Data objects\n\nimport scala.util.Random\nimport scala.math.BigDecimal\n\ncase class MakeModel(make: String, model: String)\n\ncase class T1(registration: String, make: String, model: String, engine_size: BigDecimal)\n\ncase class T2(make: String, model: String, engine_size: BigDecimal, sale_price: Double)\n\n    val makeModelSet: Seq[MakeModel] = Seq(\n      MakeModel(\"FORD\", \"FIESTA\")\n      , MakeModel(\"NISSAN\", \"QASHQAI\")\n      , MakeModel(\"HYUNDAI\", \"I20\")\n      , MakeModel(\"SUZUKI\", \"SWIFT\")\n      , MakeModel(\"MERCEDED_BENZ\", \"E CLASS\")\n      , MakeModel(\"VAUXHALL\", \"CORSA\")\n      , MakeModel(\"FIAT\", \"500\")\n      , MakeModel(\"SKODA\", \"OCTAVIA\")\n      , MakeModel(\"KIA\", \"RIO\")\n    )\n\n    def randomMakeModel(): MakeModel = {\n      val makeModelIndex = if (Random.nextBoolean()) 0 else Random.nextInt(makeModelSet.size)\n      makeModelSet(makeModelIndex)\n    }\n\n    def randomEngineSize() = BigDecimal(s\"1.${Random.nextInt(9)}\")\n\n    def randomRegistration(): String = s\"${Random.alphanumeric.take(7).mkString(\"\")}\"\n\n    def randomPrice() = 500 + Random.nextInt(5000)\n\n    def randomT1(): T1 = {\n      val makeModel = randomMakeModel()\n      T1(randomRegistration(), makeModel.make, makeModel.model, randomEngineSize())\n    }\n\n    def randomT2(): T2 = {\n      val makeModel = randomMakeModel()\n      T2(makeModel.make, makeModel.model, randomEngineSize(), randomPrice())\n    }\n\n    val t1 = Seq.fill(10000)(randomT1()).toDS()\n\n    val t2 = Seq.fill(100000)(randomT2()).toDS()\n\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"767feaf5-0189-4cb9-b7fd-5854d77f1b63"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["%scala\n// Lab 02b: Setup for Skew Partitions:  Write to File\n\nt1.write.format(\"parquet\").mode(\"overwrite\").save(\"dbfs:/FileStore/tables/t1\")\nt2.write.format(\"parquet\").mode(\"overwrite\").save(\"dbfs:/FileStore/tables/t2\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"590d7d4b-b300-42df-978a-2d30c1e1cdef"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["%scala\n// Lab 02c: Load the Data\n\nval t1DF = spark.read.parquet(\"dbfs:/FileStore/tables/t1\")\nval t2DF = spark.read.parquet(\"dbfs:/FileStore/tables/t2\")\n\nspark.read.parquet(\"dbfs:/FileStore/tables/t1\").createOrReplaceTempView(\"t1_view\")\nspark.read.parquet(\"dbfs:/FileStore/tables/t2\").createOrReplaceTempView(\"t2_view\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"107a7c7e-e3f2-4531-8a98-3f17b6dd495a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["%sql\n-- Lab 02d: Notice Skew for 'Ford Fiesta'. It has 10x rows compared to others\nSELECT make, model, count(*) AS cnt FROM t2_view GROUP BY make, model ORDER BY cnt DESC"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b5d2caf5-2fd2-4f8b-a507-81af6e78fcf2"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["%scala\n// Lab 02e: View Spark UI to find Bottleneck.  It's a Skew Partition issue (2 minute query)\n\nimport org.apache.spark.sql.functions._\n\n// We disable Broadcast join and AQE, then JOIN on 'make' and 'model'\n// In order to see our Skew happening, we need to suppress this behaviour\nspark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", -1)\nspark.conf.set(\"spark.sql.adaptive.enabled\", false)\n\n// Skew eats up 2 Minutes in one of the Stages.  Ouch!!\ndisplay(t1DF.join(t2DF, Seq(\"make\", \"model\"))\n.filter(abs(t2DF(\"engine_size\") - t1DF(\"engine_size\")) <= BigDecimal(\"0.1\"))\n  .groupBy(\"registration\")\n  .agg(avg(\"sale_price\").as(\"average_price\")).collect())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"71f57225-e145-4511-affa-910533ba8b8f"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["%scala\n// Lab 02f: Using 'hint' to minimize Skew\n\n// Ensure that AQE is disabled\nspark.conf.set(\"spark.sql.adaptive.enabled\", false)\nspark.conf.set(\"spark.sql.adaptive.skewedJoin.enabled\", false)\n\n// See 'hint' near end of code\nval t2DF = spark.read.parquet(\"dbfs:/FileStore/tables/t2\").hint(\"skew\", \"model\", (\"fiesta\"))\n\ndisplay(t1DF.join(t2DF, Seq(\"make\", \"model\"))\n.filter(abs(t2DF(\"engine_size\") - t1DF(\"engine_size\")) <= BigDecimal(\"0.1\"))\n  .groupBy(\"registration\")\n  .agg(avg(\"sale_price\").as(\"average_price\")))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7d7fdeb1-eb05-436c-a445-e1ceb783511b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["%scala\n// Lab 02g: Let AQE and let it figure out the Skew problem and fix it automatically\n// First configure the Settings\n\nimport org.apache.spark.sql.functions._\n\n// We disable Broadcast join and enable AQE\n// In order to see our skew happening, we need to suppress this behaviour\nspark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", -1)\nspark.conf.set(\"spark.sql.adaptive.enabled\", true)\n\n// I added this to see if it would work\n// Disable coalesce Partitions so Skew occurs\nspark.conf.set(\"spark.sql.adaptive.coalescePartitions.enabled\", false)\nspark.conf.set(\"spark.sql.shuffle.partitions\", 200)\n\n// A Partition is considered as skewed if its size is larger than this factor multiplying \n// The median partition size and also larger than //spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes\nspark.conf.set(\"spark.sql.adaptive.skewedPartitionFactor\", 2)\n\n// A Partition is considered  skewed if its size in bytes is larger than this threshold and larger than spark.sql.adaptive.skewJoin\n// skewedPartitionFactor multiplying the median partition size. \n//Ideally this config should be set larger than spark.sql.adaptive.advisoryPartitionSizeInBytes.\n// Was 1KB, then 124 (1.95)\nspark.conf.set(\"spark.sql.adaptive.advisoryPartitionSizeInBytes\", \"1MB\")\n// Was 4KB then 512\nspark.conf.set(\"spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes\",\"1MB\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"501d6050-ca5d-42fa-a5b7-5148e90b1f0d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["%scala\n// Lab 02h: Solution: Let AQE figure out the Skew problem and fix it automatically\n// Keep tweaking above settings to get better Performance here\n\ndisplay(t1DF.join(t2DF, Seq(\"make\", \"model\"))\n.filter(abs(t2DF(\"engine_size\") - t1DF(\"engine_size\")) <= BigDecimal(\"0.1\"))\n  .groupBy(\"registration\")\n  .agg(avg(\"sale_price\").as(\"average_price\")))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"88a0f848-a4f9-43e7-9820-d2557578d263"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["%scala\n// Lab 02i: Fix Skew by adding 'Engine_Size' to JOIN key to get more evenly Partitions\n//          This is similar to 'salt' to get more evenly sized Partitions\n//\n display(t1DF.withColumn(\"engine_size\", explode(array($\"engine_size\" - BigDecimal(\"0.1\"), \n                                           $\"engine_size\", $\"engine_size\" + BigDecimal(\"0.1\")))) \n  .join(t2DF, Seq(\"make\", \"model\", \"engine_size\")) \n  .groupBy(\"registration\")\n  .agg(avg(\"sale_price\").as(\"average_price\")))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bae9ad15-8442-4a64-9426-9d9146e4334e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["## Lab 03: Shuffle"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"76347829-696a-4d2e-b6f5-56daf2c0b055"}}},{"cell_type":"code","source":["# Lab 03a: Configure settings first\n# Disable IO cache so as to minimize side effects\nspark.conf.set(\"spark.databricks.io.cache.enabled\", False)\n\n# Disable Broadcast Hash Join\nspark.sql(\"SET spark.sql.autoBroadcastJoinThreshold = -1\")    \n\n# Enable Bucketing\nspark.sql(\"SET spark.sql.sources.bucketing.enabled=true\") \n\n# Disable AQE\nspark.conf.set(\"spark.sql.adaptive.enabled\",False)\n\n# Encourage SortMergeJoin\nspark.conf.set(\"spark.sql.join.preferSortMergeJoin\", True)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"35ddece1-02b3-4937-97e0-3aaf7c7918cc"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# Lab 03b: Read in Data\nfDF = (spark.read\n  .option(\"header\", True)\n  .option(\"inferSchema\", True)\n  .csv(\"dbfs:/databricks-datasets/asa/small/small.csv\"))\n\nfDF.createOrReplaceTempView(\"fly_view\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f8268340-8c42-4288-87cd-830a5373cfb7"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["%sql\n-- Lab 03c: Create 1st Bucket Table\nDROP TABLE IF EXISTS fly_bucket;\n\nCREATE TABLE fly_bucket(tailnum string, carrier string) \nUSING CSV\nCLUSTERED BY(tailnum) INTO 42 BUCKETS;"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d74a31d4-bda2-4162-8dc5-383ee5e6f0f8"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["%sql\n-- Lab 03d: Populate 1st Bucket Table\nINSERT INTO fly_bucket (tailnum, carrier) SELECT TailNum, UniqueCarrier from fly_view"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a571b95c-f431-4d96-aa4e-fa77afb62666"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["%sql\n-- Lab 03e: Confirm contents of 1st Bucket Table\nSELECT * FROM fly_bucket;"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f744b2fc-e5ad-4ac1-b401-da3b02dc411d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# Lab 03f: Load 2nd View\npDF = (spark.read\n  .option(\"header\", True)\n  .option(\"inferSchema\", True)\n  .csv(\"dbfs:/databricks-datasets/asa/planes/plane-data.csv\"))\n\npDF.createOrReplaceTempView(\"plane_view\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8ee53897-d828-44f5-81fd-2a6d16f5aebd"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["%sql\n-- Lab 03g: Create 2nd Bucket Table (so we can JOIN later on)\nDROP TABLE IF EXISTS plane_bucket;\n\nCREATE TABLE plane_bucket( tailnum string, manufacturer string) \nUSING CSV\nCLUSTERED BY(tailnum) INTO 42 BUCKETS;"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"aa807556-8db5-47fa-9ad7-3ac9cbf5a3e6"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["%sql\n-- Lab 03h: Populate 2nd Bucket Table\nINSERT INTO plane_bucket SELECT tailnum, manufacturer FROM plane_view;"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"645970c9-b63a-45da-8e5f-c00aebcbe4e8"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["%sql\n-- Lab 03i: Confirm contents of 2nd Bucket Table\nSELECT * FROM plane_bucket;"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"abd85e2b-600d-431b-a682-66c8679aa8eb"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["%sql\n-- Lab 03j: Without Buckets have Shuffle\nSELECT f.tailnum, p.manufacturer FROM fly_view f JOIN plane_view p ON f.tailnum = p.tailnum"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5aa0d003-3100-4fb8-887e-5cd5df64a1fe"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["%sql\n-- Lab 03k: With Buckets, don't have Shuffle\nSELECT f.tailnum, p.manufacturer FROM fly_bucket f JOIN plane_bucket p ON f.tailnum = p.tailnum"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"56239486-1475-45f7-8dc3-52a430608d1f"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["## Lab 04: Storage"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"aec3f9d6-8c5e-455e-a900-bd5947917376"}}},{"cell_type":"markdown","source":["### Data Skipping (SELECT)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bf526fd8-dc21-474b-889d-db4120c4f439"}}},{"cell_type":"code","source":["# Lab 04a: Create 2 DataFrames (one as CSV, one as Delta)\nfrom pyspark.sql.types import StructType, StructField, StringType\n\npoliceSchema = StructType([StructField('IncidentNum', StringType(), True), StructField('Category', StringType(), True), StructField('Description', StringType(), True), StructField('DayOfWeek', StringType(), True), StructField('Date', StringType(), True), StructField('Time', StringType(), True), StructField('PdDistrict', StringType(), True),  StructField('Resolution', StringType(), True), StructField('Address', StringType(), True), StructField('X', StringType(), True), StructField('Y', StringType(), True), StructField('Loc', StringType(), True), StructField('PdId', StringType(), True)])\n\nCSVdf = spark.read.schema(policeSchema).csv(\"dbfs:/FileStore/tables/sfpd1/\")\ndisplay(CSVdf)\n\nCSVdf.write.format(\"delta\").mode(\"overwrite\").save(\"/tmp/delta_cops\")\nDeltaDF = spark.read.format(\"delta\").load(\"/tmp/delta_cops\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3a70f06d-c439-43ed-a422-372e8f9be1cb"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# Lab 04b: Attempt Column Pruning on CSV File formats \n# Go to Spark UI, SQL tab. How  many MB of data was read?  \ndisplay(CSVdf.select(\"Category\", \"DayOfWeek\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"67ced3e2-cf4e-4b33-bfd0-1435e49fc10a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# Lab 04c: Column Pruning via Columnar format on Delta File formats (2 of 2)\n# Go to Spark UI, SQL tab. How  many MB of data where read?  \ndisplay(DeltaDF.select(\"Category\", \"DayOfWeek\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f064d562-ec0f-4793-a1e4-6224adfabffa"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["### Data Skipping (WHERE)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b7b5038f-d748-49ac-87f0-2e947674cb02"}}},{"cell_type":"code","source":["#  Lab 04d: If wish to repeat, run these first so don't get any conflicts\ndbutils.fs.rm(\"dbfs:/tmp/delta_cops\",True)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a75c815b-8053-47ee-8d69-213cd4c4b05c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# Lab 04e: How many files in the Directory? (20 files)\ndisplay(dbutils.fs.ls(\"dbfs:/FileStore/tables/sfpd1/\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f24fd6f0-dda3-41c7-8a8f-d2b686e0c239"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# Lab 04f: Create 2 DataFrames (one as CSV, one as Delta)\nfrom pyspark.sql.types import StructType, StructField, StringType\n\npoliceSchema = StructType([StructField('IncidentNum', StringType(), True), StructField('Category', StringType(), True), StructField('Description', StringType(), True), StructField('DayOfWeek', StringType(), True), StructField('Date', StringType(), True), StructField('Time', StringType(), True), StructField('PdDistrict', StringType(), True),  StructField('Resolution', StringType(), True), StructField('Address', StringType(), True), StructField('X', StringType(), True), StructField('Y', StringType(), True), StructField('Loc', StringType(), True), StructField('PdId', StringType(), True)])\n\nCSVdf = spark.read.schema(policeSchema).csv(\"dbfs:/FileStore/tables/sfpd1/\")\ndisplay(CSVdf)\n\nCSVdf.write.format(\"delta\").mode(\"overwrite\").save(\"/tmp/delta_cops\")\nDeltaDF = spark.read.format(\"delta\").load(\"/tmp/delta_cops\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"34b83ee5-2dcf-49ab-8025-894f87ffda4e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# Lab 04g: Attempt Data Skipping on CSV File formats (1 of 2)\n# Go to Spark UI, SQL tab.  How  many of 20 files where read?  \ndisplay(CSVdf.where(\"IncidentNum < 015046293\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f275c0ba-4e0e-40a4-8381-5baa3b042c8e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# Lab 04h: Note Delta keeps Metadata files located under Directory /_delta_log\n#          It uses these Statistics to skip reading these Files if not in query\ndisplay(spark.read.json(\"dbfs:/tmp/delta_cops/_delta_log/00000000000000000000.json\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6743a347-9b80-402c-9cfe-6b047a37a852"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# Lab 04i: Data Skipping on Delta File formats (2 of 2)\n# Go to Spark UI, SQL tab.  How  many of 20 files where read?  \ndisplay(DeltaDF.where(\"IncidentNum < 015046293\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b924a715-aa3b-47b8-91eb-be499a1bb07a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["### Best File Size on Disk (via 'optimize')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9454fbaf-6314-42b6-b53a-9e5c431f2686"}}},{"cell_type":"code","source":["# Lab 04j: Best File size on Disk (Total: 12GB in '/airlines' Directory)\n#          Want 500MB files on Disk\n# WARNING: This query takes 40 minutes. Do NOT Run\n\n# df = (spark.read.csv(\"dbfs:/databricks-datasets/asa/airlines/\")\n#          .repartition(48)\n#          .write.mode(\"overwrite\")\n#          .format(\"delta\")\n#          .save(\"/tmp/deltaPart/\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"83bc13aa-7168-4b48-b92e-a351c4aa0235"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# Lab 04k: Optimize \nflights = (spark.read.format(\"csv\") \n  .option(\"header\", \"true\") \n  .option(\"inferSchema\", \"true\") \n  .load(\"/databricks-datasets/asa/airlines/2008.csv\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9cb8ec29-11d7-4871-8d66-0dbc13e49ab2"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# Lab 04l: Optimize: Write into Delta (2 minutes)\n(flights.write.format(\"delta\")\n              .mode(\"overwrite\")\n              .save(\"dbfs:/tmp/flights_delta/\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2131e29c-1e69-4b97-b694-6e8921bec218"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# Lab 04m: Optimize: Here's the DELTA directories before OPTIMIZE (9 directories - Avg = 16MB)\ndisplay(dbutils.fs.ls(\"tmp/flights_delta\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"33770419-b955-4519-b5ef-764a77c2294f"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# Lab 04n: Optimize \n# Before Compact: Find Top 10 cities with highest monthly flights on 1st day of the week\n\nfrom pyspark.sql.functions import count\nflights_delta = spark.read.format(\"delta\").load(\"dbfs:/tmp/flights_delta/\")\ndisplay(flights_delta.filter(\"DayOfWeek = 1\").groupBy(\"Month\",\"Origin\").agg(count(\"*\").alias(\"TotalFlights\")).orderBy(\"TotalFlights\", ascending=False).limit(10))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"add32da4-603d-478d-a6e2-ccf068a4f2de"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# Lab 04o: Optimize: \nspark.sql(\"DROP TABLE IF EXISTS flights_delta\")\n\nspark.sql(\"\"\"\nCREATE TABLE flights_delta\nUSING DELTA \nLOCATION 'dbfs:/tmp/flights_delta'\n\"\"\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3f500d06-1c92-43f3-951c-995abaf885a8"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["%sql\n-- # Lab 04p: Optimize: This will do a Compaction (bin-packing) only (2-1/2 min)\nOPTIMIZE flights_delta"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"751261a7-b186-46fb-8706-a2a0e0a9db62"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# # Lab 04q: Optimize: Here's the DELTA directories after OPTIMIZE (10 Files - Got 1 giant File from Compaction)\n# So I can now VACUUM to get rid of the old directories I no longer need\ndisplay(dbutils.fs.ls(\"tmp/flights_delta\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"65ab7d5a-a551-4205-a58b-03d2d5552534"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# Lab 04r: Optimize: Enables me to remove files less than week old but keep last one\nspark.sql(\"SET spark.databricks.delta.retentionDurationCheck.enabled=false\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b58e85db-34ae-4a2c-a374-856315684056"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["%sql\n-- Lab 04s: Optimize: Remove older files and retain just one File we created via Optimize\nVACUUM flights_delta RETAIN 0 hours"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"22bd042f-944b-4a0d-ac56-be493b770869"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# Lab 04t: Optimize: Here's the DELTA directories after OPTIMIZE (10 Files down to 1 File)\ndisplay(dbutils.fs.ls(\"tmp/flights_delta\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"32259ff0-738a-4a48-9151-df63d227f054"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# Lab 04u: Optimize: After Compaction Optimization. Compare Clock time to Cell 58\ndisplay(flights_delta.filter(\"DayOfWeek = 1\").groupBy(\"Month\",\"Origin\").agg(count(\"*\").alias(\"TotalFlights\")).orderBy(\"TotalFlights\", ascending=False).limit(10))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a9ebc165-8956-403e-87c5-e933374dcd6d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["###  'optimize' using Z-Order"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"aff2a9ef-ce48-436e-bc89-e5605218d916"}}},{"cell_type":"code","source":["%sql\n-- Lab 04v: Now 'ZORDER'\nOPTIMIZE flights_delta ZORDER BY (DayofWeek)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c5a32cd5-6ae5-4cf9-961b-1f3a1e4baa96"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# Lab 04w: After ZORDER Optimization. Compare Clock time to Cell 65\ndisplay(flights_delta.filter(\"DayOfWeek = 1\").groupBy(\"Month\",\"Origin\").agg(count(\"*\").alias(\"TotalFlights\")).orderBy(\"TotalFlights\", ascending=False).limit(10))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8782fd28-8e29-41b9-90f1-539a47245389"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["### Partitoned Tables and DataFrames"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"550b997a-c37e-46f2-9f98-53647addd10c"}}},{"cell_type":"code","source":["# Lab 04x: Read in a DataFrame\nflight_nonPart = (spark.read\n  .option(\"header\", True)\n  .option(\"inferSchema\", True)\n  .csv(\"dbfs:/databricks-datasets/asa/small/small.csv\"))\n\nflight_nonPart.createOrReplaceTempView(\"flight_view_nonPart\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1939862d-f13e-44fd-be73-49d151289351"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# Lab 04y: Create a Partitioned DataFrame\nflight_nonPart.write.mode(\"overwrite\").format(\"delta\").partitionBy(\"UniqueCarrier\").save(\"/tmp/flight_part/\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"edfec24b-b10c-44d4-bbbb-a4672712aebf"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# Lab 043z: Confirm each 'UniqueCarrier' has a Disk Directory\ndisplay(dbutils.fs.ls(\"dbfs:/tmp/flight_part/\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0fe974d5-d84e-432d-b46c-8c401ad25eb0"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# Lab 04aa: Load Partitioned DataFrame and Table\n\nflight_Part = (spark.read.format(\"delta\").load(\"dbfs:/tmp/flight_part/\"))\nfDF.createOrReplaceTempView(\"flight_view_part\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b0dd27f4-2cab-42fa-8110-57eed7c96245"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# Lab 04bb: Compare Clock times of Non-Part to Part\n# NonPart is a full file scan\ndisplay(spark.sql(\"SELECT * FROM flight_view_nonPart WHERE UniqueCarrier = 'DL'\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"29bbb5a2-3a9c-4f34-a8ef-d11e411f4986"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# Lab 04cc: Compare Clock times of Non-Part to Part\n# Only scan 1 File Partition\ndisplay(spark.sql(\"SELECT * FROM flight_view_part WHERE UniqueCarrier = 'DL'\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e17abef5-0aa9-4008-b917-bf2bec75ad6c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["### Bloom Filters (WARNING: Long-running queries)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"107a5f54-1927-45ac-9088-204ceb93a22c"}}},{"cell_type":"code","source":["# Lab 04dd: Disable IO cache so as to minimize side effects\nspark.conf.set(\"spark.databricks.io.cache.enabled\", False)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2ae4b335-7419-476b-8cf6-217542d20a13"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["%sql\n-- Lab 04ee: Enable Bloom filter capability\nSET spark.databricks.io.skipping.bloomFilter.enabled = true;"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e73c01bd-6df2-4df1-bb73-a4438a844508"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["%sql\n-- Lab 04ff: Create Table\nCREATE OR REPLACE TABLE bloom_test (\n  id   BIGINT NOT NULL,\n  str1 STRING NOT NULL,\n  sha  STRING NOT NULL,\n  sha1 STRING NOT NULL,\n  sha2_256 STRING NOT NULL,\n  row_hash_too_big STRING NOT NULL,\n  row_hash STRING NOT NULL\n)\nUSING DELTA\nLOCATION 'dbfs:/tmp/bloom_test'"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"98f67622-5f8a-4de6-bce9-4e48696c319f"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["%sql\n-- Lab 04gg: Create Index before adding Data\nCREATE BLOOMFILTER INDEX\nON TABLE bloom_test\nFOR COLUMNS(sha OPTIONS (fpp=0.1, numItems=50000000))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bf724a58-e2d1-48cd-aaca-c1d450c2bd58"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["%sql\n-- Lab 04hh: Generate Data\nTRUNCATE TABLE bloom_test;\n\nWITH sample (\n  SELECT\n    id,\n    'windows.exe' as str1,\n    monotonically_increasing_id() mono_id,\n    hash(id) hash,\n    sha (cast(id % 50000000 as string)) sha,\n    sha1(cast(id % 50000000 as string)) sha1,\n    sha2(cast(id as string), 256)    sha2_256\n  from\n    RANGE(0, 10000000, 1, 448)  -- start, end, step, numPartitions\n)\nINSERT INTO bloom_test \nSELECT id, \n  str1, \n  sha,\n  sha1,\n  sha2_256,\n  sha2(concat_ws('||',id, str1, mono_id, hash, sha, sha1, sha2_256),512) row_hash_too_big,\n  sha2(concat_ws('||',id, str1, mono_id, hash, sha, sha1, sha2_256),256) row_hash\nFROM sample\nLIMIT 20000"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0ca893b8-0994-4e5e-9cf8-1a00c8e2fd21"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["%sql\n-- Lab 04ii: If add Index and there's already Data there, must Optimize to build out the Bloom Filter\n-- The default value is 1073741824, which sets the size to 1 GB. \nSET spark.databricks.delta.optimize.maxFileSize = 1610612736;\nOPTIMIZE bloom_test\nZORDER BY id"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"598ae940-1c88-4dd0-a5ad-77d50f048b0e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# Lab 04jj: Examine the Bloom index via '_delta_index' directory\ndisplay(dbutils.fs.ls(\"dbfs:/tmp/bloom_test\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c1b49f82-d5f2-49c0-acd0-abe250234b0f"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# Lab 04kk: Examine the Bloom index via '_delta_index' directory\ndisplay(dbutils.fs.ls(\"dbfs:/tmp/bloom_test/_delta_index/\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cd4c1e27-e614-4ffc-8c10-7c2211427d0c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["%sql\n-- Lab 04ll: Find some 'sha' values\nSELECT * FROM bloom_test WHERE id in ( 0, 1, 99999998, 99999999)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2ff2f836-e7ec-4316-bd5b-039e91be64aa"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["%sql\n-- Lab 04mm: Query a Non-Bloom column\n-- Might be lucky and do some Data Skipping (SELECT) since we are using Delta\nSELECT sha1 FROM bloom_test WHERE sha1 = 'b6589fc6ab0dc82cf12099d1c2d40ab994e8410c'"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"dd4dff9c-8590-4a12-99cb-708b8c35bb4a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["%sql\n-- Lab 04nn: Query a Bloom column\nSELECT sha FROM bloom_test WHERE sha = '356a192b7913b04c54574d18c28d46e6395428ab'"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5ed94a96-2ac4-4c20-8df2-e625999211b7"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["%sql\n-- Lab 04oo: Search Bloom column for something that is not there\nSELECT count(*) FROM bloom_test WHERE sha = '356a192b7913b04c54574d18c28d46e6395428ab'"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bac5e5fe-9a1d-43a3-8286-451f89342844"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["## Lab 05: Serialization"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a558427e-aae0-4e7e-b701-b1a4e93cf4e7"}}},{"cell_type":"code","source":["%scala\n// Lab 05a: Using lower level 'flatMap' which forces Serialization/Deserialization\nimport org.apache.spark.sql._\nimport org.apache.spark.sql.types._\n\nval arrayStructureData = Seq(\n    Row(\"James,Smith\",List(\"Java\",\"Scala\",\"C++\"),\"CA\"),\n    Row(\"Michael,Rose,\",List(\"Spark\",\"Java\",\"C++\"),\"NJ\"),\n    Row(\"Robert,Williams\",List(\"CSharp\",\"VB\",\"R\"),\"NV\")\n)\n\nval arrayStructureSchema = new StructType()\n    .add(\"name\",StringType)\n    .add(\"languages\", ArrayType(StringType))\n    .add(\"state\", StringType)\n\nval df = spark.createDataFrame(\nspark.sparkContext.parallelize(arrayStructureData),arrayStructureSchema)\nimport spark.implicits._"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"646d7e73-d7e0-4ee8-8d21-4a18ecd48efb"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["%scala\n// Lab 05b:  Here's the Data\ndf.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c5eb02a5-a633-45f1-8ba4-0c1e62c4e172"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["%scala\n// Lab 05c: Using Lower level function flatMap().  Go to Spark UI > SQL tab and look for Deserialization\nval df2=df.flatMap(f=> f.getSeq[String](1).map((f.getString(0),_,f.getString(2))))\n    .toDF(\"name\",\"language\",\"state\")\n\ndf2.show(false)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9dec46e6-5a48-4787-89c3-7764e4e8f32d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["%scala\n// Lab 05d: Using Higher-leve function 'explode' (Java Optimized)\n// Compare Clock times\nimport org.apache.spark.sql.functions.explode\ndf.select($\"name\", explode($\"languages\"), $\"state\").show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a7ff9f00-f89d-40f6-bebd-a1426b83dd00"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["# End of Module 10: Performance Tuning\n# Ignore past here"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b66b8d47-f6a3-47b7-86bd-4c65b2c2197f"}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Mod-10-Perf_Tuning!","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":3262131266600660}},"nbformat":4,"nbformat_minor":0}
